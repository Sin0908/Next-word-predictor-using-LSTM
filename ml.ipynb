{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (2.14.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (3.6 kB)\n",
      "Collecting tensorflow-macos==2.15.0 (from tensorflow)\n",
      "  Downloading tensorflow_macos-2.15.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.58.0)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.2.2)\n",
      "Downloading tensorflow-2.15.0-cp310-cp310-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Downloading tensorflow_macos-2.15.0-cp310-cp310-macosx_12_0_arm64.whl (208.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.8/208.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorflow-estimator, tensorboard, tensorflow-macos, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.14.0\n",
      "    Uninstalling tensorflow-estimator-2.14.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.14.1\n",
      "    Uninstalling tensorboard-2.14.1:\n",
      "      Successfully uninstalled tensorboard-2.14.1\n",
      "  Attempting uninstall: tensorflow-macos\n",
      "    Found existing installation: tensorflow-macos 2.14.0\n",
      "    Uninstalling tensorflow-macos-2.14.0:\n",
      "      Successfully uninstalled tensorflow-macos-2.14.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.14.0\n",
      "    Uninstalling tensorflow-2.14.0:\n",
      "      Successfully uninstalled tensorflow-2.14.0\n",
      "Successfully installed tensorboard-2.15.1 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-macos-2.15.0\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade keras\n",
    "! pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.15.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages\n",
      "Requires: tensorflow-macos\n",
      "Required-by: tf-models-official\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4843\n",
      "The Length of sequences are:  32771\n",
      "Data:  [[  1  51 109]\n",
      " [ 51 109 306]\n",
      " [109 306   3]\n",
      " [306   3   4]\n",
      " [  3   4  47]\n",
      " [  4  47 331]\n",
      " [ 47 331  27]\n",
      " [331  27 306]\n",
      " [ 27 306  32]\n",
      " [306  32  17]]\n",
      "Response:  [306   3   4  47 331  27 306  32  17   1]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 10)             48430     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4843)              4847843   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17945273 (68.46 MB)\n",
      "Trainable params: 17945273 (68.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 6.7179\n",
      "Epoch 1: loss improved from inf to 6.71792, saving model to next_words.h5\n",
      "513/513 [==============================] - 54s 102ms/step - loss: 6.7179\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saisindhusangavi/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513/513 [==============================] - ETA: 0s - loss: 6.2292\n",
      "Epoch 2: loss improved from 6.71792 to 6.22917, saving model to next_words.h5\n",
      "513/513 [==============================] - 52s 102ms/step - loss: 6.2292\n",
      "Epoch 3/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 5.8224\n",
      "Epoch 3: loss improved from 6.22917 to 5.82238, saving model to next_words.h5\n",
      "513/513 [==============================] - 53s 103ms/step - loss: 5.8224\n",
      "Epoch 4/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 5.4831\n",
      "Epoch 4: loss improved from 5.82238 to 5.48314, saving model to next_words.h5\n",
      "513/513 [==============================] - 53s 104ms/step - loss: 5.4831\n",
      "Epoch 5/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 5.1971\n",
      "Epoch 5: loss improved from 5.48314 to 5.19710, saving model to next_words.h5\n",
      "513/513 [==============================] - 57s 112ms/step - loss: 5.1971\n",
      "Epoch 6/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 4.9426\n",
      "Epoch 6: loss improved from 5.19710 to 4.94265, saving model to next_words.h5\n",
      "513/513 [==============================] - 56s 109ms/step - loss: 4.9426\n",
      "Epoch 7/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 4.7159\n",
      "Epoch 7: loss improved from 4.94265 to 4.71590, saving model to next_words.h5\n",
      "513/513 [==============================] - 55s 106ms/step - loss: 4.7159\n",
      "Epoch 8/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 4.4595\n",
      "Epoch 8: loss improved from 4.71590 to 4.45954, saving model to next_words.h5\n",
      "513/513 [==============================] - 53s 104ms/step - loss: 4.4595\n",
      "Epoch 9/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 4.1962\n",
      "Epoch 9: loss improved from 4.45954 to 4.19618, saving model to next_words.h5\n",
      "513/513 [==============================] - 53s 103ms/step - loss: 4.1962\n",
      "Epoch 10/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 3.8930\n",
      "Epoch 10: loss improved from 4.19618 to 3.89304, saving model to next_words.h5\n",
      "513/513 [==============================] - 56s 109ms/step - loss: 3.8930\n",
      "Epoch 11/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 3.5779\n",
      "Epoch 11: loss improved from 3.89304 to 3.57792, saving model to next_words.h5\n",
      "513/513 [==============================] - 55s 108ms/step - loss: 3.5779\n",
      "Epoch 12/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 3.2656\n",
      "Epoch 12: loss improved from 3.57792 to 3.26564, saving model to next_words.h5\n",
      "513/513 [==============================] - 57s 111ms/step - loss: 3.2656\n",
      "Epoch 13/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 2.9728\n",
      "Epoch 13: loss improved from 3.26564 to 2.97282, saving model to next_words.h5\n",
      "513/513 [==============================] - 57s 111ms/step - loss: 2.9728\n",
      "Epoch 14/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 2.7065\n",
      "Epoch 14: loss improved from 2.97282 to 2.70653, saving model to next_words.h5\n",
      "513/513 [==============================] - 56s 110ms/step - loss: 2.7065\n",
      "Epoch 15/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 2.4572\n",
      "Epoch 15: loss improved from 2.70653 to 2.45720, saving model to next_words.h5\n",
      "513/513 [==============================] - 56s 110ms/step - loss: 2.4572\n",
      "Epoch 16/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 2.2344\n",
      "Epoch 16: loss improved from 2.45720 to 2.23439, saving model to next_words.h5\n",
      "513/513 [==============================] - 57s 110ms/step - loss: 2.2344\n",
      "Epoch 17/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 2.0299\n",
      "Epoch 17: loss improved from 2.23439 to 2.02994, saving model to next_words.h5\n",
      "513/513 [==============================] - 58s 113ms/step - loss: 2.0299\n",
      "Epoch 18/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 1.8307\n",
      "Epoch 18: loss improved from 2.02994 to 1.83071, saving model to next_words.h5\n",
      "513/513 [==============================] - 58s 113ms/step - loss: 1.8307\n",
      "Epoch 19/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 1.6534\n",
      "Epoch 19: loss improved from 1.83071 to 1.65341, saving model to next_words.h5\n",
      "513/513 [==============================] - 60s 116ms/step - loss: 1.6534\n",
      "Epoch 20/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 1.4900\n",
      "Epoch 20: loss improved from 1.65341 to 1.49004, saving model to next_words.h5\n",
      "513/513 [==============================] - 61s 118ms/step - loss: 1.4900\n",
      "Epoch 21/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 1.3134\n",
      "Epoch 21: loss improved from 1.49004 to 1.31336, saving model to next_words.h5\n",
      "513/513 [==============================] - 61s 118ms/step - loss: 1.3134\n",
      "Epoch 22/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 1.1787\n",
      "Epoch 22: loss improved from 1.31336 to 1.17869, saving model to next_words.h5\n",
      "513/513 [==============================] - 58s 113ms/step - loss: 1.1787\n",
      "Epoch 23/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 1.0303\n",
      "Epoch 23: loss improved from 1.17869 to 1.03032, saving model to next_words.h5\n",
      "513/513 [==============================] - 62s 121ms/step - loss: 1.0303\n",
      "Epoch 24/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 0.8838\n",
      "Epoch 24: loss improved from 1.03032 to 0.88381, saving model to next_words.h5\n",
      "513/513 [==============================] - 60s 117ms/step - loss: 0.8838\n",
      "Epoch 25/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 0.7734\n",
      "Epoch 25: loss improved from 0.88381 to 0.77344, saving model to next_words.h5\n",
      "513/513 [==============================] - 62s 122ms/step - loss: 0.7734\n",
      "Epoch 26/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 0.6990\n",
      "Epoch 26: loss improved from 0.77344 to 0.69904, saving model to next_words.h5\n",
      "513/513 [==============================] - 64s 124ms/step - loss: 0.6990\n",
      "Epoch 27/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 0.6383\n",
      "Epoch 27: loss improved from 0.69904 to 0.63833, saving model to next_words.h5\n",
      "513/513 [==============================] - 60s 116ms/step - loss: 0.6383\n",
      "Epoch 28/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 0.5586\n",
      "Epoch 28: loss improved from 0.63833 to 0.55859, saving model to next_words.h5\n",
      "513/513 [==============================] - 59s 115ms/step - loss: 0.5586\n",
      "Epoch 29/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 0.5027\n",
      "Epoch 29: loss improved from 0.55859 to 0.50269, saving model to next_words.h5\n",
      "513/513 [==============================] - 60s 117ms/step - loss: 0.5027\n",
      "Epoch 30/30\n",
      "513/513 [==============================] - ETA: 0s - loss: 0.4627\n",
      "Epoch 30: loss improved from 0.50269 to 0.46269, saving model to next_words.h5\n",
      "513/513 [==============================] - 59s 115ms/step - loss: 0.4627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16e5cb790>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "file = open(\"/Users/saisindhusangavi/Desktop/ML LAB/christmascarol.txt\", \"r\", encoding = \"utf8\")\n",
    " \n",
    "# store file in list\n",
    "lines = []\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    " \n",
    "# Convert list to string\n",
    "data = \"\"\n",
    "for i in lines:\n",
    "  data = ' '. join(lines) \n",
    " \n",
    "#replace unnecessary stuff with space\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')  #new line, carriage return, unicode character --> replace by space\n",
    " \n",
    "#remove unnecessary spaces \n",
    "data = data.split()\n",
    "data = ' '.join(data)\n",
    "data[:500]\n",
    "len(data)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    " \n",
    "# saving the tokenizer for predict function\n",
    "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
    " \n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "sequence_data[:15]\n",
    "len(sequence_data)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)\n",
    "sequences = []\n",
    " \n",
    "for i in range(3, len(sequence_data)):\n",
    "    words = sequence_data[i-3:i+1]\n",
    "    sequences.append(words)\n",
    "     \n",
    "print(\"The Length of sequences are: \", len(sequences))\n",
    "sequences = np.array(sequences)\n",
    "sequences[:10]\n",
    "X = []\n",
    "y = []\n",
    " \n",
    "for i in sequences:\n",
    "    X.append(i[0:3])\n",
    "    y.append(i[3])\n",
    "     \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"Data: \", X[:10])\n",
    "print(\"Response: \", y[:10])\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y[:5]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=3))\n",
    "model.add(LSTM(1000, return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "plot_model(model, to_file='plot.png', show_layer_names=True)\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    " \n",
    "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "model.fit(X, y, epochs=30, batch_size=64, callbacks=[checkpoint])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 10)             48430     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4843)              4847843   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17945273 (68.46 MB)\n",
      "Trainable params: 17945273 (68.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "model = load_model('next_words.h5')\n",
    "print(model.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
